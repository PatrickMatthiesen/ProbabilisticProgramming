{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import rethinking as rt\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "rng = np.random.default_rng(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Probabilistic Programming. Wasowski. Pardo. IT University of Copenhagen__\n",
    "\n",
    "This file contains the list of exercises for the week, as well as any related code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "The exercises for this week are: __all exercises__ from Chapter 4, McElreath, with exceptions and remarks noted below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Exercise 4M2__ asks for using `quap`. We do not use `quap` in this course. We use MCMC instead (`pymc.sampling.sample` does that). There is really no benefit to quadratic approximation which is only locally correct, and only gives us key summary statistics. If we can manage to achieve a full posterior sample, we have more information at hand.  If you have a good sample trace from 4M1, you can just call `arviz.summary` on it to get the mean and standard deviation from our parameters (which `quap` would give us). cf. https://arviz-devs.github.io/arviz/api/generated/arviz.summary.html\n",
    "* __Exercise 4M7__ uses model m4.3. The model uses data, so first the data loading code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Howell1.csv', sep=';').to_xarray()\n",
    "adults = data.where(data.age >= 18, drop = True)# condition on adults\n",
    "adults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model in PyMC syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbar = adults.weight.data.mean()\n",
    "with pm.Model() as m4_3:\n",
    "\n",
    "    # Prior\n",
    "    α = pm.Normal('α', mu = 178, sigma = 20) \n",
    "    β = pm.LogNormal('β', mu = 0, sigma = 1)\n",
    "    σ  = pm.Uniform('σ', 0, 50)\n",
    "    \n",
    "    # Ignore for now, think of it as x. We could have used x, but this allows to do prediction later.\n",
    "    x_mutable = pm.Data(\"x\", adults.weight.values)\n",
    "    \n",
    "    # The linear model\n",
    "    μ = pm.Deterministic('μ', α + β*(x_mutable-xbar))\n",
    "    \n",
    "    # The likelihood:\n",
    "    height = pm.Normal('height', mu = μ, sigma = σ, observed = adults.height.data) \n",
    "    idata_m4_3 = pm.sample(draws=3000, random_seed = rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exercise __4M8__ is about splines. We have not talked about this in the lecture, and you can safely skip it if your only guidance is exam curriculum.  Otherwise it is a fascinating exercise, so feel free to look into  it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exercise __4H2__ uses the Howell dataset again. It is loaded above into `data` and `adults`. You probably want to reuse the model formulation from above, too.  As usual, use the pPyMC sampler, not quadratic approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exercise __4H3__ in part (b) refers to an R plot that might look mysterious to you.  Just use the same kind of plot as in __4H2__. This is what they mean :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The parabolic model Exercise __4H4__ talks about is the one found on p. 111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exercise __4H5__ is using the cherry Blosom data from p. 114. Below is the code to load it. Also the exercise is unclear which regression to use. Since we are trying to de-emphasize splines, try just with usual linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(\"cherry_blossoms.csv\").to_xarray()\n",
    "# if you want to drop NAs:\n",
    "d = pd.read_csv(\"cherry_blossoms.csv\").dropna().to_xarray()\n",
    "\n",
    "# summary stats the rethinking way\n",
    "print(rt.precis(d))\n",
    "\n",
    "# summary stats the pandas way\n",
    "pd.read_csv(\"cherry_blossoms.csv\").dropna().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary stats the arviz way\n",
    "az.summary(pd.read_csv(\"cherry_blossoms.csv\").dropna().to_dict(orient=\"list\"), kind=\"stats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exercise __4H6__ is asking for cherry Blosom spline fitting, while we are trying to de-emphasize splines in the course a bit (the course is sufficiently large as it is already).  Instead try to generate prior predictive from a linear regression from 4H5 (just to train the concept). Use the prior predictive distribution to assess the choice of priors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Skip exercise __4H8__, as it is purely about splines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
